# DreamTone ğŸµ

<p align="center">
  <img src="./frontend/public/images/hero-image.jpg" alt="DreamTone Logo" width="300"/>
</p>

<p align="center">
  <strong>Generate unique, AI-powered music from text descriptions, lyrics, and more, all from a unified Next.js application.</strong>
  <br />
  <a href="#-features"><strong>Explore the features Â»</strong></a>
  <br />
  <br />
  <a href="#-getting-started">Getting Started</a> Â· <a href="#-contributing">Contribute</a>

</p>

## ğŸ¶ About The Project

**DreamTone** is an intelligent music generator that transforms your creative ideas into original melodies and compositions. Whether you're a musician suffering from writer's block, a content creator in need of a unique soundtrack, or just curious about the power of AI in music, DreamTone provides the tools to bring your auditory concepts to life.

This application leverages artificial intelligence to generate music based on three flexible input methods: a simple song description, your own lyrics, or lyrics generated by AI.

## ğŸ›ï¸ Architecture

This project is a **full-stack application built entirely with Next.js**.

- The **Frontend UI** is a modern React application built with Next.js App Router.
- The **Backend Logic** is handled by **Next.js API Routes**, which are deployed as serverless functions. This provides a scalable, efficient, and integrated backend without the need for a separate, constantly running server.

Some of the more intensive AI processing or other backend tasks may be handled by standalone serverless functions, which are called from the Next.js API routes.

## ğŸ” Features

- **Music from Description**: Describe the mood, genre, tempo, or instruments (e.g., "A melancholic, slow-paced piano melody"), and the AI will compose it.
- **Lyrics-to-Song**: Provide your own lyrics, and DreamTone will generate a musical composition that matches the emotion and structure of your words.
- **AI-Generated Lyrics**: Don't have lyrics? The app can generate creative, context-aware lyrics and then set them to music.
- **Customizable Outputs**: Fine-tune the generated music by specifying different styles and instruments.
- **Serverless & Scalable**: Built to handle dynamic traffic loads efficiently.
- **Reliable Background Processing**: Music generation is handled as a background job via Inngest, so you can close the app and the job will still complete.

## ğŸ› ï¸ Technologies Used

- **Core Framework**: Next.js (for both UI and API)
- **Frontend**: React, TypeScript, Tailwind CSS
- **Backend**: Next.js, API Routes (Serverless Functions), Inngest
- **AI/ML**: Hugging Face, a Python serverless functions (using Modal)
- **Storage**: AWS S3

## ğŸš€ Getting Started

To get a local copy up and running, follow these simple steps.

### Prerequisites

Make sure you have Node.js and a package manager installed.

- Node.js (v18.0 or later)
- npm, yarn, or pnpm

### Installation

1.  **Clone the repo**
    ```
    git clone https://github.com/j-mahapatra/dreamtone.git
    ```
2.  **Navigate to the project directory**
    ```
    cd dreamtone
    ```
3.  **Navigate to frontend folder**

    ```
    cd frontend
    ```

4.  **Install dependencies**
    ```
    npm install
    ```
5.  **Set up Environment Variables**
    Create a `.env` file using the `.env.example` add your necessary API keys and configuration:

## ğŸ¤ Contributing

Contributions are what make the open-source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag "enhancement".

1.  Fork the Project
2.  Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3.  Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4.  Push to the Branch (`git push origin feature/AmazingFeature`)
5.  Open a Pull Request

## ğŸ“„ License

Distributed under the MIT License. See [`LICENSE`](./LICENSE) for more information.

## ğŸƒ Usage

Once installed, you can start the development server.

1.  **Run the development server**

    ```
    npm run dev
    ```

    This command starts both the frontend UI and the backend API routes.

2.  **Open the application**
    Open your browser and navigate to `http://localhost:3000`.

## âœ¨ Models Used

- [Qwen/Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct) for audio generation
- [stabilityai/sdxl-turbo](https://huggingface.co/stabilityai/sdxl-turbo) for image generation
